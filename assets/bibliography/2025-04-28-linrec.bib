@article{ladner1980parallelprefix,
  title={Parallel prefix computation},
  author={Ladner, Richard E and Fischer, Michael J},
  journal={Journal of the ACM (JACM)},
  volume={27},
  number={4},
  pages={831--838},
  year={1980},
  publisher={ACM New York, NY, USA},
  url={https://dl.acm.org/doi/10.1145/322217.322232}
}

@article{blelloch1990prefixapplication,
  title={Prefix sums and their applications},
  author={Blelloch, Guy E},
  year={1990},
  publisher={School of Computer Science, Carnegie Mellon University Pittsburgh, PA, USA},
  url={https://www.cs.cmu.edu/~guyb/papers/Ble93.pdf}
}

@article{bradbury2016qrnn,
  title={Quasi-recurrent neural networks},
  author={Bradbury, James and Merity, Stephen and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1611.01576},
  year={2016}
}

@inproceedings{lei2018sru,
    title = "Simple Recurrent Units for Highly Parallelizable Recurrence",
    author = "Lei, Tao and Zhang, Yu and Wang, Sida I. and Dai, Hui and Artzi, Yoav",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    year = "2018",
    url = "https://arxiv.org/abs/1709.02755"
}

@inproceedings{martin2018parallelizing,
title={Parallelizing Linear Recurrent Neural Nets Over Sequence Length},
author={Eric Martin and Chris Cundy},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://arxiv.org/abs/1709.04057},
}


@inproceedings{gu2022s4,
  title={Efficiently Modeling Long Sequences with Structured State Spaces},
  author={Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  booktitle={International Conference on Learning Representations (ICLR 2022)},
  year={2022},
  eprint={2111.00396},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2111.00396}
}

@inproceedings{smith2023s5,
title={Simplified State Space Layers for Sequence Modeling},
author={Jimmy T.H. Smith and Andrew Warrington and Scott Linderman},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://arxiv.org/abs/2208.04933}
}


@inproceedings{orvieto2023lru,
  title={Resurrecting recurrent neural networks for long sequences},
  author={Orvieto, Antonio and Smith, Samuel L and Gu, Albert and Fernando, Anushan and Gulcehre, Caglar and Pascanu, Razvan and De, Soham},
  booktitle={International Conference on Machine Learning},
  year={2023},
  url={https://arxiv.org/abs/2303.06349}
}

@article{gu2024mamba,
      title={Mamba: Linear-Time Sequence Modeling with Selective State Spaces}, 
      author={Albert Gu and Tri Dao},
      booktitle={First Conference on Language Modeling},
      year={2024},
      eprint={2312.00752},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2312.00752}, 
}

@inproceedings{dao2024mamba2,
  title={{Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality}},
  author={Dao, Tri and Gu, Albert},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}



@inproceedings{rush2022annotatedS4,
  title = {The Annotated S4},
  author = {Rush, Alexander and Karamcheti, Sidd},
  booktitle = {ICLR Blog Track},
  year = {2022},
  url  = {https://iclr-blog-track.github.io/2022/03/25/annotated-s4/}
}

@article{chen2024mamba,
  title = {Mamba No. 5 (A Little Bit Of...)},
  author = {Chen, James},
  year = {2024},
  url  = {https://jameschen.io/jekyll/update/2024/02/12/mamba.html}
}

@article{grootendorst2024mamba,
  title = {A Visual Guide to Mamba and State Space Models},
  author = {Grootendorst, Maarten},
  year = {2024},
  url  = {https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state}
}

@article{rush2024mamba,
  title = {Mamba: The Hard Way},
  author = {Rush, Alexander},
  year = {2024},
  url  = {https://srush.github.io/annotated-mamba/hard.html}
}









@book{kirk2016programming,
  title={Programming massively parallel processors: a hands-on approach},
  author={Kirk, David B and Wen-Mei, W Hwu},
  year={2016},
  publisher={Morgan kaufmann}
}


@article{merrill2016cubscan,
  title={Single-pass parallel prefix scan with decoupled look-back},
  author={Merrill, Duane and Garland, Michael},
  journal={NVIDIA, Tech. Rep. NVR-2016-002},
  year={2016}
}








@article{stablessm,
  title={Stability analysis and stabilization of fuzzy state space models},
  author={Kim, Won Chul and Ahn, Sang Chul and Kwon, Wook Hyun},
  journal={Fuzzy sets and systems},
  volume={71},
  number={1},
  pages={131--142},
  year={1995},
  publisher={Elsevier}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{dl,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@article{firstrnn,
  title={Learning internal representations by error propagation, parallel distributed processing, explorations in the microstructure of cognition, ed. de rumelhart and j. mcclelland. vol. 1. 1986},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={Biometrika},
  volume={71},
  number={599-607},
  pages={6},
  year={1986}
}

@article{deltanet,
  title={Parallelizing Linear Transformers with the Delta Rule over Sequence Length},
  author={Yang, Songlin and Wang, Bailin and Zhang, Yu and Shen, Yikang and Kim, Yoon},
  journal={arXiv preprint arXiv:2406.06484},
  year={2024}
}

@article{rwkv,
  title={{RWKV: Reinventing RNNs for the Transformer era}},
  author={Peng, Bo and Alcaide, Eric and Anthony, Quentin and Albalak, Alon and Arcadinho, Samuel and Biderman, Stella and Cao, Huanqi and Cheng, Xin and Chung, Michael and Grella, Matteo and others},
  journal={arXiv preprint arXiv:2305.13048},
  year={2023}
}

@article{theoretical_ssm,
  title={Theoretical foundations of deep selective state-space models},
  author={Cirone, Nicola Muca and Orvieto, Antonio and Walker, Benjamin and Salvi, Cristopher and Lyons, Terry},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}

@inproceedings{zoology,
  title={Zoology: Measuring and Improving Recall in Efficient Language Models},
  author={Arora, Simran and Eyuboglu, Sabri and Timalsina, Aman and Johnson, Isys and Poli, Michael and Zou, James and Rudra, Atri and Re, Christopher},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{nguyen2024sequence,
  title={Sequence modeling and design from molecular to genome scale with Evo},
  author={Nguyen, Eric and Poli, Michael and Durrant, Matthew G and Thomas, Armin W and Kang, Brian and Sullivan, Jeremy and Ng, Madelena Y and Lewis, Ashley and Patel, Aman and Lou, Aaron and others},
  journal={BioRxiv},
  pages={2024--02},
  year={2024},
  publisher={Cold Spring Harbor Laboratory}
}

@article{vmamba,
  title={Vision mamba: Efficient visual representation learning with bidirectional state space model},
  author={Zhu, Lianghui and Liao, Bencheng and Zhang, Qian and Wang, Xinlong and Liu, Wenyu and Wang, Xinggang},
  journal={arXiv preprint arXiv:2401.09417},
  year={2024}
}

@article{biot,
  title={Biot: Biosignal transformer for cross-data learning in the wild},
  author={Yang, Chaoqi and Westover, M and Sun, Jimeng},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@article{vim,
  title={{Vision Mamba: Efficient visual representation learning with bidirectional state space model}},
  author={Zhu, Lianghui and Liao, Bencheng and Zhang, Qian and Wang, Xinlong and Liu, Wenyu and Wang, Xinggang},
  journal={arXiv preprint arXiv:2401.09417},
  year={2024}
}


@inproceedings{sashimi,
  title={Itâ€™s raw! audio generation with state-space models},
  author={Goel, Karan and Gu, Albert and Donahue, Chris and R{\'e}, Christopher},
  booktitle={International Conference on Machine Learning},
  pages={7616--7633},
  year={2022},
  organization={PMLR}
}

@article{hydra,
  title={Hydra: Bidirectional state space models through generalized matrix mixers},
  author={Hwang, Sukjun and Lahoti, Aakash and Dao, Tri and Gu, Albert},
  journal={arXiv preprint arXiv:2407.09941},
  year={2024}
}

@inproceedings{lineartransfomer,
  title={{Transformers are RNNs: Fast autoregressive transformers with linear attention}},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={International conference on machine learning},
  pages={5156--5165},
  year={2020},
  organization={PMLR}
}

@inproceedings{bert,
  title={{BERT: Pre-training of deep bidirectional transformers for language understanding}},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of naacL-HLT},
  volume={1},
  pages={2},
  year={2019},
  organization={Minneapolis, Minnesota}
}

@article{flashatt,
  title={{FlashAttention: Fast and memory-efficient exact attention with IO-awareness}},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16344--16359},
  year={2022}
}

@article{flashatt3,
  title={{FlashAttention-3: Fast and accurate attention with asynchrony and low-precision}},
  author={Shah, Jay and Bikshandi, Ganesh and Zhang, Ying and Thakkar, Vijay and Ramani, Pradeep and Dao, Tri},
  journal={arXiv preprint arXiv:2407.08608},
  year={2024}
}









@article{lstm,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

@article{gru,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.1078},
  year={2014}
}

@article{lra,
  title={Long range arena: A benchmark for efficient transformers},
  author={Tay, Yi and Dehghani, Mostafa and Abnar, Samira and Shen, Yikang and Bahri, Dara and Pham, Philip and Rao, Jinfeng and Yang, Liu and Ruder, Sebastian and Metzler, Donald},
  journal={arXiv preprint arXiv:2011.04006},
  year={2020}
}

@misc{vit,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@article{llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}




@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{sutton2019bitterlesson,
  title={The bitter lesson},
  author={Sutton, Richard},
  journal={Incomplete Ideas (blog)},
  volume={13},
  number={1},
  pages={38},
  year={2019}
}

@article{hooker2021hardwarelottery,
  title={The hardware lottery},
  author={Hooker, Sara},
  journal={Communications of the ACM},
  volume={64},
  number={12},
  pages={58--65},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{merrill2024illusion,
  title={The Illusion of State in State-Space Models},
  author={Merrill, William and Petty, Jackson and Sabharwal, Ashish},
  booktitle={International Conference on Machine Learning},
  year={2024}
}
