
@article{dijkstra1985anthropomorphism,
  title={On anthropomorphism in science},
  author={Dijkstra, Edsger W},
  journal={EWD936, Sept},
  year={1985}
}
@article{hancock2020ai,
  title={AI-mediated communication: Definition, research agenda, and ethical considerations},
  author={Hancock, Jeffrey T and Naaman, Mor and Levy, Karen},
  journal={Journal of Computer-Mediated Communication},
  volume={25},
  number={1},
  pages={89--100},
  year={2020},
  publisher={Oxford University Press}
}
@book{malm2016fossil,
  title={Fossil capital: The rise of steam power and the roots of global warming},
  author={Malm, Andreas},
  year={2016},
  publisher={Verso books}
}
@article{shneidermandumpty,
	title = {A nonanthropomorphic style guide: overcoming the Humpty Dumpty syndrome},
	journal = {Sparks of innovation in human-computer interaction},
	year = {1993},
	pages = {331 - 331},
	author = {Shneiderman, Ben}
}
@article{lingel2020alexa,
  title={Alexa, tell me about your mother: The history of the secretary and the end of secrecy},
  author={Lingel, Jessa and Crawford, Kate},
  journal={Catalyst: Feminism, Theory, Technoscience},
  volume={6},
  number={1},
  year={2020}
}

@INPROCEEDINGS{Emnett2024-na,
  title     ={Using Robot Social Agency Theory to Understand Robots' Linguistic
               Anthropomorphism},
  author    ={Emnett, Cloe Z and Mott, Terran and Williams, Tom},
  booktitle ={Companion of the 2024 ACM/IEEE International Conference on
               Human-Robot Interaction},
  publisher ={Association for Computing Machinery},
  address   ={New York, NY, USA},
  pages     ={447--452},
  abstract  ={Robots' use of natural language is one of the key factors that
               leads humans to anthropomorphize them. But it is not yet well
               understood what types of language most lead to such
               language-based anthropomorphization (or, Linguistic
               Anthropomorphism). In this paper, we present a brief literature
               survey that suggests six broad categories of linguistic factors
               that lead humans to anthropomorphize robots: autonomy,
               adaptability, directness, politeness, proportionality, and humor.
               By contextualizing these six factors through the lens of Jackson
               and Williams' Theory of Social Agency for Human-Robot
               Interaction, we are able to show how and why these particular
               factors are those responsible for language-based robot
               anthropomorphism.},
  series    ={HRI '24},
  month     =  mar,
  year      =  2024,
  keywords  ={linguistic anthropomorphism, social agency}
}

@article{Roose.2024,
 author  = {Roose, Kevin},
 date    = {2024-10-23},
 title   = {Can A.I. Be Blamed for a Teens Suicide?},
 journal = {The New York Times},
 url     = {https://www.nytimes.com/2024/10/23/technology/characterai-lawsuit-teen-suicide.html},
year={2024},
}

@inproceedings{jones-bergen-2024-gpt,
    title ={Does {GPT}-4 pass the {T}uring test?},
    author ={Jones, Cameron  and
      Bergen, Ben},
    editor ={Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven},
    booktitle ={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
    month = jun,
    year ={2024},
    address ={Mexico City, Mexico},
    publisher ={Association for Computational Linguistics},
    url ={https://aclanthology.org/2024.naacl-long.290},
    doi ={10.18653/v1/2024.naacl-long.290},
    pages ={5183--5210},
}
@article{Porra2020-dq,
  title={Can computer based human-likeness endanger humanness? A philosophical and ethical perspective on digital assistants expressing feelings they cant have},
  author={Porra, Jaana and Lacity, Mary and Parks, Michael S},
  journal={Information Systems Frontiers},
  volume={22},
  pages={533--547},
  year={2020},
  publisher={Springer}
}

@ARTICLE{Chien2024-vl,
  title         ={Beyond Behaviorist Representational Harms: A Plan for
                   Measurement and Mitigation},
  author        ={Chien, Jennifer and Danks, David},
  journal       ={arXiv [cs.CY]},
  abstract      ={Algorithmic harms are commonly categorized as either
                   allocative or representational. This study specifically
                   addresses the latter, focusing on an examination of current
                   definitions of representational harms to discern what is
                   included and what is not. This analysis motivates our
                   expansion beyond behavioral definitions to encompass harms to
                   cognitive and affective states. The paper outlines high-level
                   requirements for measurement: identifying the necessary
                   expertise to implement this approach and illustrating it
                   through a case study. Our work highlights the unique
                   vulnerabilities of large language models to perpetrating
                   representational harms, particularly when these harms go
                   unmeasured and unmitigated. The work concludes by presenting
                   proposed mitigations and delineating when to employ them. The
                   overarching aim of this research is to establish a framework
                   for broadening the definition of representational harms and
                   to translate insights from fairness research into practical
                   measurement and mitigation praxis.},
  month         =  jan,
  year          =  2024,
  archivePrefix ={arXiv},
  primaryClass  ={cs.CY}
}
@article{payne.2024,
 author  = {Payne, Kate},
 date    = {2024-10-25},
year={2024},
 title   = {An AI chatbot pushed a teen to kill himself, a lawsuit against its creator alleges
},
 journal = {The Associated Press},
 url     = {https://apnews.com/article/chatbot-ai-lawsuit-suicide-teen-artificial-intelligence-9d48adc572100822fdbc3c90d1456bd0},
 urldate = {2024-10-26}
}
@article{khattab2023dspy,
  title={Dspy: Compiling declarative language model calls into self-improving pipelines},
  author={Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T and Moazam, Hanna and others},
  journal={arXiv preprint arXiv:2310.03714},
  year={2023}
}
@article{zhang2022robustness,
  title={Robustness of demonstration-based learning under limited data scenario},
  author={Zhang, Hongxin and Zhang, Yanzhe and Zhang, Ruiyi and Yang, Diyi},
  journal={arXiv preprint arXiv:2210.10693},
  year={2022}
}
@article{zhi2024beyond,
  title={Beyond Preferences in {AI} Alignment},
  author={Zhi-Xuan, Tan and Carroll, Micah and Franklin, Matija and Ashton, Hal},
  journal={Philosophical Studies},
  pages={1--51},
  year={2024},
  publisher={Springer}
}
@book{berkeley1949giant,
  title={Giant brains; or, Machines that think},
  author={Berkeley, Edmund Callis},
  year={1949},
  publisher={Wiley}
}
@article{hewitt2024instruction,
  title={Instruction following without instruction tuning},
  author={Hewitt, John and Liu, Nelson F and Liang, Percy and Manning, Christopher D},
  journal={arXiv preprint arXiv:2409.14254},
  year={2024}
}
@article{gros2022robots,
  title={Robots-dont-cry: understanding falsely anthropomorphic utterances in dialog systems},
  author={Gros, David and Li, Yu and Yu, Zhou},
  journal={arXiv preprint arXiv:2210.12429},
  year={2022}
}
@article{west2023comparing,
  title={Comparing Google Bard with OpenAIs ChatGPT on political bias, facts, and morality},
  author={West, Darrell M},
  year={2023},
  journal={The Brookings Institution}
}
