@article{dijkstra1985anthropomorphism,
  title={On anthropomorphism in science},
  author={Dijkstra, Edsger W},
  journal={EWD936, Sept},
  year={1985}
}
@article{hancock2020ai,
  title={AI-mediated communication: Definition, research agenda, and ethical considerations},
  author={Hancock, Jeffrey T and Naaman, Mor and Levy, Karen},
  journal={Journal of Computer-Mediated Communication},
  volume={25},
  number={1},
  pages={89--100},
  year={2020},
  publisher={Oxford University Press}
}
@book{malm2016fossil,
  title={Fossil capital: The rise of steam power and the roots of global warming},
  author={Malm, Andreas},
  year={2016},
  publisher={Verso books}
}
@article{shneidermandumpty,
	title = {A nonanthropomorphic style guide: overcoming the Humpty Dumpty syndrome},
	journal = {Sparks of innovation in human-computer interaction},
	year = {1993},
	pages = {331 - 331},
	author = {Shneiderman, Ben}
}
@article{lingel2020alexa,
  title={Alexa, tell me about your mother”: The history of the secretary and the end of secrecy},
  author={Lingel, Jessa and Crawford, Kate},
  journal={Catalyst: Feminism, Theory, Technoscience},
  volume={6},
  number={1},
  year={2020}
}
@INPROCEEDINGS{Emnett2024-na,
  title     ={Using Robot Social Agency Theory to Understand Robots' Linguistic
               Anthropomorphism},
  author    ={Emnett, Cloe Z and Mott, Terran and Williams, Tom},
  booktitle ={Companion of the 2024 ACM/IEEE International Conference on
               Human-Robot Interaction},
  publisher ={Association for Computing Machinery},
  address   ={New York, NY, USA},
  pages     ={447--452},
  abstract  ={Robots' use of natural language is one of the key factors that
               leads humans to anthropomorphize them. But it is not yet well
               understood what types of language most lead to such
               language-based anthropomorphization (or, Linguistic
               Anthropomorphism). In this paper, we present a brief literature
               survey that suggests six broad categories of linguistic factors
               that lead humans to anthropomorphize robots: autonomy,
               adaptability, directness, politeness, proportionality, and humor.
               By contextualizing these six factors through the lens of Jackson
               and Williams' Theory of Social Agency for Human-Robot
               Interaction, we are able to show how and why these particular
               factors are those responsible for language-based robot
               anthropomorphism.},
  series    ={HRI '24},
  month     =  mar,
  year      =  2024,
  keywords  ={linguistic anthropomorphism, social agency}
}

@ARTICLE{Porra2020-dq,
  title    ={“Can Computer Based Human-Likeness Endanger Humanness?” – A
              Philosophical and Ethical Perspective on Digital Assistants
              Expressing Feelings They Can’t Have”},
  author   ={Porra, Jaana and Lacity, Mary and Parks, Michael S},
  journal  ={Inf. Syst. Front.},
  volume   =  22,
  number   =  3,
  pages    ={533--547},
  abstract ={Digital assistants engage with us with increasingly human-like
              conversations, including the expression of human emotions with
              such utterances as “I am sorry…”, “I hope you enjoy…”, “I am
              grateful…”, or “I regret that…”. By 2021, digital assistants will
              outnumber humans. No one seems to stop to ask if creating more
              digital companions that appear increasingly human is really
              beneficial to the future of our species. In this essay, we pose
              the question: “How human should computer-based human-likeness
              appear?” We rely on the philosophy of humanness and the theory of
              speech acts to consider the long-term consequences of living with
              digital creatures that express human-like feelings. We argue that
              feelings are the very substance of our humanness and therefore are
              best reserved for human interaction.},
  month    =  jun,
  year     =  2020
}

@article{Roose.2024,
 author  = {Roose, Kevin},
 date    = {2024-10-23},
 title   = {Can {A.I.} Be Blamed for a Teen’s Suicide?},
 journal = {The New York Times},
 url     = {https://www.nytimes.com/2024/10/23/technology/characterai-lawsuit-teen-suicide.html},
year={2024},
}
@inproceedings{jones-bergen-2024-gpt,
    title ={Does {GPT}-4 pass the {T}uring test?},
    author ={Jones, Cameron  and
      Bergen, Ben},
    editor ={Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven},
    booktitle ={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
    month = jun,
    year ={2024},
    address ={Mexico City, Mexico},
    publisher ={Association for Computational Linguistics},
    url ={https://aclanthology.org/2024.naacl-long.290},
    doi ={10.18653/v1/2024.naacl-long.290},
    pages ={5183--5210},
    abstract ={We evaluated GPT-4 in a public online Turing test. The best-performing GPT-4 prompt passed in 49.7{\%} of games, outperforming ELIZA (22{\%}) and GPT-3.5 (20{\%}), but falling short of the baseline set by human participants (66{\%}). Participants{'} decisions were based mainly on linguistic style (35{\%}) and socioemotional traits (27{\%}), supporting the idea that intelligence, narrowly conceived, is not sufficient to pass the Turing test. Participant knowledge about LLMs and number of games played positively correlated with accuracy in detecting AI, suggesting learning and practice as possible strategies to mitigate deception. Despite known limitations as a test of intelligence, we argue that the Turing test continues to be relevant as an assessment of naturalistic communication and deception. AI models with the ability to masquerade as humans could have widespread societal consequences, and we analyse the effectiveness of different strategies and criteria for judging humanlikeness.},
}
