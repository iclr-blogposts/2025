@inproceedings{he23solving,
  title={Solving Math Word Problems by Combining Language Models With Symbolic Solvers},
  author={He-Yueya, Joy and Poesia, Gabriel and Wang, Rose and Goodman, Noah},
  booktitle={The 3rd Workshop on Mathematical Reasoning and AI at NeurIPS'23}
}


@inproceedings{gurreal,
  title={A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis},
  author={Gur, Izzeddin and Furuta, Hiroki and Huang, Austin V and Safdari, Mustafa and Matsuo, Yutaka and Eck, Douglas and Faust, Aleksandra},
  booktitle={The Twelfth International Conference on Learning Representations}
}



@inproceedings{NEURIPS2023_d842425e,
 author = {Schick, Timo and Dwivedi-Yu, Jane and Dessi, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {68539--68551},
 publisher = {Curran Associates, Inc.},
 title = {Toolformer: Language Models Can Teach Themselves to Use Tools},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/d842425e4bf79ba039352da0f658a906-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}




@InProceedings{pmlr-v202-gao23f,
  title = 	 {{PAL}: Program-aided Language Models},
  author =       {Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {10764--10799},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/gao23f/gao23f.pdf},
  url = 	 {https://proceedings.mlr.press/v202/gao23f.html},
}



@inproceedings{yao2022react,
  title={ReAct: Synergizing Reasoning and Acting in Language Models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Shafran, Izhak and Narasimhan, Karthik R and Cao, Yuan},
  booktitle={NeurIPS 2022 Foundation Models for Decision Making Workshop}
}


@inproceedings{NEURIPS2023_e3936777,
 author = {Yang, Rui and Song, Lin and Li, Yanwei and Zhao, Sijie and Ge, Yixiao and Li, Xiu and Shan, Ying},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {71995--72007},
 publisher = {Curran Associates, Inc.},
 title = {GPT4Tools: Teaching Large Language Model to Use Tools via Self-instruction},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/e393677793767624f2821cec8bdd02f1-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}


@inproceedings{valmeekam2022large,
title={Large Language Models Still Can't Plan (A Benchmark for {LLM}s on Planning and Reasoning about Change)},
author={Karthik Valmeekam and Alberto Olmo and Sarath Sreedharan and Subbarao Kambhampati},
booktitle={NeurIPS 2022 Foundation Models for Decision Making Workshop},
year={2022},
url={https://openreview.net/forum?id=wUU-7XTL5XO}
}

@article{xu2023large,
  title={Are large language models really good logical reasoners? a comprehensive evaluation from deductive, inductive and abductive views},
  author={Xu, Fangzhi and Lin, Qika and Han, Jiawei and Zhao, Tianzhe and Liu, Jun and Cambria, Erik},
  journal={arXiv preprint arXiv:2306.09841},
  year={2023}
}

@inproceedings{10.1145/3627673.3679832,
author = {Amirizaniani, Maryam and Martin, Elias and Sivachenko, Maryna and Mashhadi, Afra and Shah, Chirag},
title = {Can LLMs Reason Like Humans? Assessing Theory of Mind Reasoning in LLMs for Open-Ended Questions},
year = {2024},
isbn = {9798400704369},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {34–44},
numpages = {11},
series = {CIKM '24}
}

@misc{arkoudas2023gpt4cantreason,
      title={GPT-4 Can't Reason}, 
      author={Konstantine Arkoudas},
      year={2023},
      eprint={2308.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.03762}, 
}

@inproceedings{merrillexpressive,
  title={The Expressive Power of Transformers with Chain of Thought},
  author={Merrill, William and Sabharwal, Ashish},
  booktitle={The Twelfth International Conference on Learning Representations}
}

@article{JMLRv2220-302,
  author  = {Jorge Perez and Pablo Barcelo and Javier Marinkovic},
  title   = {Attention is Turing-Complete},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {75},
  pages   = {1--35},
  url     = {http://jmlr.org/papers/v22/20-302.html}
}

@inproceedings{deletang2023neural,
title={Neural Networks and the Chomsky Hierarchy},
author={Gregoire Deletang and Anian Ruoss and Jordi Grau-Moya and Tim Genewein and Li Kevin Wenliang and Elliot Catt and Chris Cundy and Marcus Hutter and Shane Legg and Joel Veness and Pedro A Ortega},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=WbxHAzkeQcn}
}

@article{10.1162/tacl_a_00562,
    author = {Merrill, William and Sabharwal, Ashish},
    title = {The Parallelism Tradeoff: Limitations of Log-Precision Transformers},
    journal = {Transactions of the Association for Computational Linguistics},
    year = {2023},
    month = {06},
}
@inproceedings{chiang2023tighter,
  title={Tighter bounds on the expressivity of transformer encoders},
  author={Chiang, David and Cholak, Peter and Pillay, Anand},
  booktitle={International Conference on Machine Learning},
  pages={5544--5562},
  year={2023},
  organization={PMLR}
}

@inproceedings{chakraborty2024transfer,
title={Transfer Q-star : Principled Decoding for {LLM} Alignment},
author={Souradip Chakraborty and Soumya Suvra Ghosal and Ming Yin and Dinesh Manocha and Mengdi Wang and Amrit Bedi and Furong Huang},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=5PrShrKxoX}
}


@inproceedings{fubreak,
  title={Break the Sequential Dependency of LLM Inference Using Lookahead Decoding},
  author={Fu, Yichao and Bailis, Peter and Stoica, Ion and Zhang, Hao},
  booktitle={Forty-first International Conference on Machine Learning}
}

@article{brown2024large,
  title={Large language monkeys: Scaling inference compute with repeated sampling},
  author={Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V and R{\'e}, Christopher and Mirhoseini, Azalia},
  journal={arXiv preprint arXiv:2407.21787},
  year={2024}
}

BibTeX Record
@inproceedings{xie2024travelplanner,
title={TravelPlanner: A Benchmark for Real-World Planning with Language Agents},
author={Jian Xie and Kai Zhang and Jiangjie Chen and Tinghui Zhu and Renze Lou and Yuandong Tian and Yanghua Xiao and Yu Su},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=l5XQzNkAOe}
}


@inproceedings{wangself,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc V and Chi, Ed H and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  booktitle={The Eleventh International Conference on Learning Representations}
}


@inproceedings{luoreasoning,
  title={Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning},
  author={LUO, LINHAO and Li, Yuan-Fang and Haf, Reza and Pan, Shirui},
  booktitle={The Twelfth International Conference on Learning Representations}
}


@inproceedings{jiang2023structgpt,
  title={StructGPT: A General Framework for Large Language Model to Reason over Structured Data},
  author={Jiang, Jinhao and Zhou, Kun and Dong, Zican and Ye, Keming and Zhao, Wayne Xin and Wen, Ji-Rong},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={9237--9251},
  year={2023}
}


@inproceedings{zhang2024llm4dyg,
author = {Zhang, Zeyang and Wang, Xin and Zhang, Ziwei and Li, Haoyang and Qin, Yijian and Zhu, Wenwu},
title = {LLM4DyG: Can Large Language Models Solve Spatial-Temporal Problems on Dynamic Graphs?},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4350–4361},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{sunthink,
  title={Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph},
  author={Sun, Jiashuo and Xu, Chengjin and Tang, Lumingyuan and Wang, Saizhuo and Lin, Chen and Gong, Yeyun and Ni, Lionel and Shum, Heung-Yeung and Guo, Jian},
  booktitle={The Twelfth International Conference on Learning Representations}
}


@inproceedings{hong2024metagpt,
title={Meta{GPT}: Meta Programming for A Multi-Agent Collaborative Framework},
author={Sirui Hong and Mingchen Zhuge and Jonathan Chen and Xiawu Zheng and Yuheng Cheng and Jinlin Wang and Ceyao Zhang and Zili Wang and Steven Ka Shing Yau and Zijuan Lin and Liyang Zhou and Chenyu Ran and Lingfeng Xiao and Chenglin Wu and J{\"u}rgen Schmidhuber},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=VtmBAGCN7o}
}


@article{li2023camel,
  title={Camel: Communicative agents for" mind" exploration of large language model society},
  author={Li, Guohao and Hammoud, Hasan and Itani, Hani and Khizbullin, Dmitrii and Ghanem, Bernard},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={51991--52008},
  year={2023}
}


@article{wangvoyager,
  title={Voyager: An Open-Ended Embodied Agent with Large Language Models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={Transactions on Machine Learning Research}
}


@article{liang2023encouraging,
  title={Encouraging divergent thinking in large language models through multi-agent debate},
  author={Liang, Tian and He, Zhiwei and Jiao, Wenxiang and Wang, Xing and Wang, Yan and Wang, Rui and Yang, Yujiu and Shi, Shuming and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2305.19118},
  year={2023}
}

@inproceedings{duimproving,
  title={Improving Factuality and Reasoning in Language Models through Multiagent Debate},
  author={Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua B and Mordatch, Igor},
  booktitle={Forty-first International Conference on Machine Learning}
}



@inproceedings{wu2024autogen,
  title={AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation},
  author={Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Li, Beibin and Zhu, Erkang and Jiang, Li and Zhang, Xiaoyun and Zhang, Shaokun and Liu, Jiale and others},
  booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents}
}


@article{LLM-as-OS,
  title={Llm as os (llmao), agents as apps: Envisioning aios, agents and the aios-agent ecosystem},
  author={Ge, Yingqiang and Ren, Yujie and Hua, Wenyue and Xu, Shuyuan and Tan, Juntao and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2312.03815},
  year={2023}
}


@inproceedings{zhoulanguage,
  title={Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models},
  author={Zhou, Andy and Yan, Kai and Shlapentokh-Rothman, Michal and Wang, Haohan and Wang, Yu-Xiong},
  booktitle={Forty-first International Conference on Machine Learning}
}


@phdthesis{ringer2021proofphd,
  title={Proof Repair (Doctoral dissertation)},
  author={Ringer, Talia},
  year={2021}
}


@inproceedings{ringer2021proof,
author = {Ringer, Talia and Porter, RanDair and Yazdani, Nathaniel and Leo, John and Grossman, Dan},
title = {Proof repair across type equivalences},
year = {2021},
isbn = {9781450383912},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
location = {Virtual, Canada},
series = {PLDI 2021}
}



@article{yao2024tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{besta2024graph,
  title={Graph of thoughts: Solving elaborate problems with large language models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17682--17690},
  year={2024}
}

@article{han2022folio,
  title={Folio: Natural language reasoning with first-order logic},
  author={Han, Simeng and Schoelkopf, Hailey and Zhao, Yilun and Qi, Zhenting and Riddell, Martin and Zhou, Wenfei and Coady, James and Peng, David and Qiao, Yujie and Benson, Luke and others},
  journal={arXiv preprint arXiv:2209.00840},
  year={2022}
}

@article{sunindeterminacy,
  title={From Indeterminacy to Determinacy: Augmenting Logical Reasoning Capabilities with Large Language Models},
  author={Sun, Hongda and Xu, Weikai and Liu, Wei and Luan, Jian and Wang, Bin and Shang, Shuo and Wen, Ji-Rong and Yan, Rui}
}


@inproceedings{sun-etal-2024-determlr,
    title = "{D}eterm{LR}: Augmenting {LLM}-based Logical Reasoning from Indeterminacy to Determinacy",
    author = "Sun, Hongda  and
      Xu, Weikai  and
      Liu, Wei  and
      Luan, Jian  and
      Wang, Bin  and
      Shang, Shuo  and
      Wen, Ji-Rong  and
      Yan, Rui",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    publisher = "Association for Computational Linguistics",
    pages = "9828--9862",
}

@inproceedings{pan-etal-2023-logic,
    title = "Logic-{LM}: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning",
    author = "Pan, Liangming  and
      Albalak, Alon  and
      Wang, Xinyi  and
      Wang, William",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    pages = "3806--3824",
}




@inproceedings{wang2024symbolic,
  title={Symbolic Working Memory Enhances Language Models for Complex Rule Application},
  author={Wang, Siyuan and Wei, Zhongyu and Choi, Yejin and Ren, Xiang},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={17583--17604},
  year={2024}
}


@inproceedings{Xu2024FaithfulLR,
  title={Faithful Logical Reasoning via Symbolic Chain-of-Thought},
  author={Jundong Xu and Hao Fei and Liangming Pan and Qian Liu and Mong Li Lee and Wynne Hsu},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:270068130}
}


Granite-Function:
Granite-Function Calling Model: Introducing Function Calling Abilities via Multi-task Learning of Granular Tasks


FreshLLMs:
FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation


AIOS:
AIOS: LLM Agent Operating System

ToolLLM
ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs


PopQA:
Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge


GSM-Symbolic:
GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models



Grokking:
Progress measures for grokking via mechanistic interpretability

Reveal-CoT:
Towards revealing the mystery behind chain of thought: a theoretical perspective


CanLLMReason:
Can Large Language Models Reason and Plan?


Memory-Augmented-Turing:
Memory Augmented Large Language Models are Computationally Universal


Autogressive-Turing:
Autoregressive Large Language Models are Computationally Universal





RecursiveReasoning:
Can Transformers Learn to Solve Problems Recursively?




MTCS-Decoding
Machine Translation Decoding beyond Beam Search





Stack-Attention:
A Transformer with Stack Attention

























